{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc646abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [11:25:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics Comparison\n",
      "               Classifier  Train Accuracy  Test Accuracy  Test Precision (Weighted)  Test Recall (Weighted)  Test F1-Score (Weighted)\n",
      "0  Support Vector Machine        0.975000       0.966667                   0.969697                0.966667                  0.966583\n",
      "1           Decision Tree        1.000000       0.933333                   0.933333                0.933333                  0.933333\n",
      "2           Random Forest        1.000000       0.900000                   0.902357                0.900000                  0.899749\n",
      "3                AdaBoost        1.000000       0.933333                   0.933333                0.933333                  0.933333\n",
      "4                 XGBoost        1.000000       0.933333                   0.933333                0.933333                  0.933333\n",
      "5                CatBoost        1.000000       0.933333                   0.933333                0.933333                  0.933333\n",
      "6    Gaussian Naive-Bayes        0.958333       0.966667                   0.969697                0.966667                  0.966583\n",
      "7          MLP Classifier        0.983333       0.966667                   0.969697                0.966667                  0.966583\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Import all the required classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "# It's important to fit the scaler ONLY on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# --- 2. Define Models ---\n",
    "models = {\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"Gaussian Naive-Bayes\": GaussianNB(),\n",
    "    \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Train and Evaluate ---\n",
    "results_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions on Training data\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    \n",
    "    # Predictions on Test data\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Store results\n",
    "    results_list.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Test Precision (Weighted)\": precision_score(y_test, y_test_pred, average='weighted'),\n",
    "        \"Test Recall (Weighted)\": recall_score(y_test, y_test_pred, average='weighted'),\n",
    "        \"Test F1-Score (Weighted)\": f1_score(y_test, y_test_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# --- 4. Display Results ---\n",
    "print(\"Performance Metrics Comparison\")\n",
    "print(results_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
